## ğŸ§  Local RAG PDF Chatbot using Streamlit + Ollama + LangChain

This project is a **fully local Retrieval-Augmented Generation (RAG)** chatbot that allows you to **upload a PDF** and **ask questions** about its content â€” all running **offline** on your system.

It uses **LangChain** for retrieval, **FAISS** for vector search, and **Ollama** to run **local LLMs** like `qwen3`, `mistral`, or `llama3` â€” ensuring **data privacy** and **zero cloud dependency**


<img width="1920" height="1020" alt="Screenshot 2025-10-18 142649" src="https://github.com/user-attachments/assets/4fe985f4-96f9-4a7e-89c3-c1106c455242" />


---

### âš¡ Key Features

* ğŸ“„ **Upload any PDF** and interact with its content
* ğŸ’¾ **Local embeddings & FAISS storage** â€” no data leaves your machine
* ğŸ¤– **Ollama local LLM integration** â€” no API keys or internet required
* ğŸ§© **LangChain-powered retrieval** for accurate context-based answers
* ğŸ’¬ **Streamlit UI** with two sections:

  * Left â†’ Upload PDF
  * Right â†’ Chat interface
* ğŸ” 100% **offline, private, and free to run**

---

### ğŸ—ï¸ Tech Stack


| Component       | Tool                             |
| --------------- | -------------------------------- |
| Language Model  | Ollama (local)                   |
| Framework       | LangChain                        |
| Vector Store    | FAISS                            |
| Embeddings      | HuggingFace (`all-MiniLM-L6-v2`) |
| UI              | Streamlit                        |
| Document Loader | PyPDFLoader                      |

---

### ğŸ“‚ Project Structure

```
ğŸ“ local-rag-chatbot
â”‚
â”œâ”€â”€ app.py                  # Streamlit UI & RAG logic
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ data/                   # Uploaded PDFs
â”œâ”€â”€ rag_index/              # Local FAISS index (auto-managed)
â””â”€â”€ README.md               # Project documentation
```

---

### âš™ï¸ Installation & Setup

#### 1ï¸âƒ£ Clone this repository

```bash
git clone https://github.com/Aakash109-hub/local-rag-assistant.git
cd local-rag-assistant
```

#### 2ï¸âƒ£ Create a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate     # (Mac/Linux)
venv\Scripts\activate        # (Windows)
```

#### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Install Ollama (for local models)

Visit ğŸ‘‰ [https://ollama.ai](https://ollama.ai)
Download and install Ollama for your OS.

#### 5ï¸âƒ£ Pull your preferred local model

```bash
ollama pull qwen3:1.7b
```

Other supported models:

* `ollama pull mistral`
* `ollama pull llama3`
* `ollama pull phi3`

#### 6ï¸âƒ£ Run the Streamlit app

```bash
streamlit run app.py
```

---

### ğŸ§  How It Works

1. **Upload PDF** â†’ The app extracts text using `PyPDFLoader`.
2. **Text Splitting** â†’ Uses `RecursiveCharacterTextSplitter` to create manageable chunks.
3. **Embedding** â†’ Generates embeddings locally using `HuggingFaceEmbeddings`.
4. **Vector Store** â†’ Saves to a **local FAISS index**.
5. **Query** â†’ Retrieves top results using similarity search.
6. **Response** â†’ Sends context and query to the **Ollama local LLM** to generate a natural answer.

ğŸ§¹ When a new PDF is uploaded, the previous FAISS index is **cleared automatically** to avoid mixing data between files.

---

### ğŸ” Why Local?

* ğŸ§¾ **No internet required**
* ğŸ§  **All data and embeddings stay on your machine**
* ğŸ’¸ **No API costs**
* âš™ï¸ **Full control** over model, indexing, and storage

This makes it perfect for **private documents, research papers, or company files** you donâ€™t want to send to the cloud.

---

### ğŸ§° Example Usage

1. Run the app:

   ```bash
   streamlit run app.py
   ```
2. Upload your PDF file (e.g., `research_paper.pdf`)
3. Ask:

   > â€œWhat is the main conclusion of this paper?â€
4. Get a **context-aware response** generated locally using Ollama.

---

### ğŸ“¸ UI Overview

| Section         | Description                        |
| --------------- | ---------------------------------- |
| **Left Panel**  | PDF Upload and Index Management    |
| **Right Panel** | Chat Interface and Model Responses |
